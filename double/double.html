<!DOCTYPE html>
<html>
<head>
  <script src="js/face-api.js"></script>
  <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
  <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> -->
</head>
<body>
  <div>Ref Image:</div>
    <img id="refImg" width="320" src="">
  <!-- <div>Query Image:</div>
    <img id="queryImg" src="./images/doubles/160748.jpg" alt=""> -->
</body>
<script>
  let faceMatcher = null


async function updateReferenceImageResults() {
  const inputImgEl = document.querySelector('#refImg')
  //const canvas = $('#refImgOverlay').get(0)

  const fullFaceDescription = await faceapi
    .detectSingleFace(inputImgEl, new faceapi.TinyFaceDetectorOptions({ inputSize, scoreThreshold}))
    .withFaceLandmarks()
    .withFaceDescriptor()

  if (!fullFaceDescription) {
    return
  }
  console.log(fullFaceDescription)

  faceMatcher = new faceapi.FaceMatcher(fullFaceDescription)
  console.log(faceMatcher)
}


async function updateQueryImageResults() {
  if (!faceMatcher) {
    return
  }

  const inputImgEl = document.querySelector('#queryImg')

  const result = await faceapi
    .detectSingleFace(inputImgEl, new faceapi.TinyFaceDetectorOptions({ inputSize, scoreThreshold}))
    .withFaceLandmarks()
    .withFaceDescriptor()

  console.log(result);
  const distance = faceMatcher.computeMeanDistance(result.descriptor, faceMatcher.labeledDescriptors[0].descriptors)
  console.log('query distance: ', distance)

}

async function updateResults() {
  await updateReferenceImageResults()
  await updateQueryImageResults()
}

async function getFaceData() {
  const faceDataOut = []
  const inputSize = 320
  const scoreThreshold = 0.2
  const inputImgEl = document.querySelector('#refImg')
  const doubleRes = await axios.get('https://bilboblockins.github.io/double/data/stunt_actors.json')
  const doubleData = doubleRes.data

  for(let i=0; i<doubleData.length; i++) {
    console.log('Processing ', doubleData[i].name, '...')
    inputImgEl.src = doubleData[i].image_path
    const faceData = await faceapi
      .detectSingleFace(inputImgEl, new faceapi.TinyFaceDetectorOptions({ inputSize, scoreThreshold}))
      .withFaceLandmarks()
      .withFaceDescriptor()
    console.log(faceData)
    faceDataOut.push(faceData.descriptor)
  }
  return faceDataOut
}

function downloadJSON(obj, fileName, contentType) {
    let jsonStr = JSON.stringify(obj)
    let a = document.createElement("a")
    let file = new Blob([jsonStr], {type: 'application/json'})
    a.href = URL.createObjectURL(file)
    a.download = fileName
    a.click()
}

//minConfidence = Math.min(faceapi.utils.round(minConfidence + 0.1), 1.0) //increase
//minConfidence = Math.max(faceapi.utils.round(minConfidence - 0.1), 0.1) //decrease
//scoreThreshold = Math.min(faceapi.utils.round(scoreThreshold + 0.1), 1.0)

async function run() {
  // load face detection, face landmark model and face recognition models
  await faceapi.loadTinyFaceDetectorModel('/double/weights/')
  await faceapi.loadFaceLandmarkModel('/double/weights/')
  await faceapi.loadFaceRecognitionModel('/double/weights/')
  
  const doublesModel = await getFaceData()
  console.log(doublesModel)
  downloadJSON(doublesModel, 'doublesModel.json')
}

run()

</script>
</html>
